# LipSync_using_wav2point

This guide provides step-by-step instructions to generate a lip-synced video using the Wav2Lip model. It also covers converting text to speech (TTS) using gTTS and image to video using FFmpeg, which are prerequisites for lip-syncing.

# Step 1: Convert Text to Speech using gTTS

Refer to the file "text_audio" for generating speech audio using gTTS.

# Step 2: Convert Image to Video using FFmpeg

Refer to the file "img_video" for converting an image into a video using FFmpeg.

# Step 3: Implement Wav2Lip for Lip Syncing

Refer to the "lipsync_collab" file for implementing the Wav2Lip model in Google Colab.

# üé• Example Output

üîó Download/Watch the Result: [" https://drive.google.com/file/d/13Yn0CoP5LYSOF9PNKK9Kay1QEcfsbF3C/view?usp=sharing "]

# ‚úÖ Summary of Steps

1Ô∏è‚É£ Convert Text to Speech (gTTS) ‚Üí Refer to text_audio
2Ô∏è‚É£ Convert Image to Video (FFmpeg) ‚Üí Refer to img_video
3Ô∏è‚É£ Run Wav2Lip to sync lips ‚Üí Refer to lipsync_collab
4Ô∏è‚É£ Play, Download & Share the generated video üé•
